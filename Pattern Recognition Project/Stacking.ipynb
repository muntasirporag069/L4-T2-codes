{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5453 files belonging to 10 classes.\n",
      "Sample of stacking features with probabilities:\n",
      "   EfficientNet_Class_0  EfficientNet_Class_1  EfficientNet_Class_2  \\\n",
      "0              0.000059              0.000290          3.303785e-02   \n",
      "1              0.284511              0.000005          3.872419e-05   \n",
      "2              0.998579              0.000001          2.129611e-07   \n",
      "3              0.741073              0.000205          3.983658e-06   \n",
      "4              0.999323              0.000003          6.519338e-07   \n",
      "\n",
      "   EfficientNet_Class_3  EfficientNet_Class_4  EfficientNet_Class_5  \\\n",
      "0          1.195257e-02              0.001914          5.050433e-01   \n",
      "1          4.781166e-05              0.000715          7.009579e-01   \n",
      "2          1.436287e-04              0.000045          9.428346e-06   \n",
      "3          4.757738e-07              0.258709          1.089334e-08   \n",
      "4          1.026797e-06              0.000035          4.204391e-05   \n",
      "\n",
      "   EfficientNet_Class_6  EfficientNet_Class_7  EfficientNet_Class_8  \\\n",
      "0              0.002141              0.001529          2.191361e-01   \n",
      "1              0.012505              0.001211          1.001819e-07   \n",
      "2              0.000891              0.000001          5.497174e-07   \n",
      "3              0.000006              0.000002          1.605196e-09   \n",
      "4              0.000561              0.000033          5.154777e-09   \n",
      "\n",
      "   EfficientNet_Class_9  ...  VGG_Class_1  VGG_Class_2   VGG_Class_3  \\\n",
      "0          2.248975e-01  ...     0.005071     0.011122  2.066402e-02   \n",
      "1          7.925145e-06  ...     0.009913     0.019509  6.907156e-03   \n",
      "2          3.289795e-04  ...     0.018649     0.005623  3.714368e-03   \n",
      "3          6.163108e-09  ...     0.105880     0.073198  4.211234e-07   \n",
      "4          1.674935e-06  ...     0.216268     0.006764  8.193800e-04   \n",
      "\n",
      "   VGG_Class_4  VGG_Class_5  VGG_Class_6  VGG_Class_7   VGG_Class_8  \\\n",
      "0     0.006969     0.647960     0.034500     0.064942  3.845452e-02   \n",
      "1     0.271509     0.009647     0.003796     0.409950  1.685356e-05   \n",
      "2     0.027789     0.064841     0.366735     0.073909  8.895817e-04   \n",
      "3     0.695345     0.000002     0.000058     0.000003  6.192569e-11   \n",
      "4     0.074159     0.000162     0.032011     0.000066  1.363394e-08   \n",
      "\n",
      "    VGG_Class_9  TrueLabel  \n",
      "0  1.686395e-01          0  \n",
      "1  2.984351e-04          0  \n",
      "2  1.879413e-01          0  \n",
      "3  6.429153e-07          0  \n",
      "4  1.333391e-04          0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "test_data_path = Path(r\"D:\\Virtual Environments\\Pattern Recognition\\segmented dataset\\meta_model_train\")\n",
    "efficientnet_model_path = Path(r\"D:\\Virtual Environments\\Pattern Recognition\\Models\\EfficientNet\")\n",
    "resnet_model_path = Path(r\"D:\\Virtual Environments\\Pattern Recognition\\Models\\ResNet\")\n",
    "vgg_model_path = Path(r\"D:\\Virtual Environments\\Pattern Recognition\\Models\\VGG\")\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 10 \n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    str(test_data_path),\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "#                         Loading base learners\n",
    "efficientnet_loaded = tf.saved_model.load(str(efficientnet_model_path))\n",
    "efficientnet_infer = efficientnet_loaded.signatures[\"serving_default\"]\n",
    "\n",
    "resnet_loaded = tf.saved_model.load(str(resnet_model_path))\n",
    "resnet_infer = resnet_loaded.signatures[\"serving_default\"]\n",
    "\n",
    "vgg_loaded = tf.saved_model.load(str(vgg_model_path))\n",
    "vgg_infer = vgg_loaded.signatures[\"serving_default\"]\n",
    "\n",
    "#            Generate probability predictions from each base learner\n",
    "efficientnet_probs = []\n",
    "resnet_probs = []\n",
    "vgg_probs = []\n",
    "true_labels = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    #                   EfficientNet probabilities\n",
    "    preds_eff = efficientnet_infer(images)\n",
    "    if isinstance(preds_eff, dict):\n",
    "        preds_eff = list(preds_eff.values())[0]\n",
    "    preds_eff = preds_eff.numpy()  \n",
    "    \n",
    "    #                     ResNet probabilities\n",
    "    preds_resnet = resnet_infer(images)\n",
    "    if isinstance(preds_resnet, dict):\n",
    "        preds_resnet = list(preds_resnet.values())[0]\n",
    "    preds_resnet = preds_resnet.numpy()  \n",
    "    \n",
    "    #                     VGG probabilities\n",
    "    preds_vgg = vgg_infer(images)\n",
    "    if isinstance(preds_vgg, dict):\n",
    "        preds_vgg = list(preds_vgg.values())[0]\n",
    "    preds_vgg = preds_vgg.numpy() \n",
    "    \n",
    "    #           Append probabilities and corresponding true labels\n",
    "    efficientnet_probs.append(preds_eff)\n",
    "    resnet_probs.append(preds_resnet)\n",
    "    vgg_probs.append(preds_vgg)\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "#                    Concatenate all probability arrays\n",
    "efficientnet_probs = np.concatenate(efficientnet_probs, axis=0)  # Shape: [N, NUM_CLASSES]\n",
    "resnet_probs = np.concatenate(resnet_probs, axis=0)\n",
    "vgg_probs = np.concatenate(vgg_probs, axis=0)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Create a pandas dataframe for stacking using model probabilities as features\n",
    "\n",
    "efficientnet_cols = [f\"EfficientNet_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "resnet_cols = [f\"ResNet_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "vgg_cols = [f\"VGG_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "df_efficientnet = pd.DataFrame(efficientnet_probs, columns=efficientnet_cols)\n",
    "df_resnet = pd.DataS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "NUM_CLASSES = 10  \n",
    "\n",
    "#           Create feature names for each base model's probability outputs\n",
    "efficientnet_cols = [f\"EfficientNet_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "resnet_cols = [f\"ResNet_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "vgg_cols = [f\"VGG_Class_{i}\" for i in range(NUM_CLASSES)]\n",
    "feature_cols = efficientnet_cols + resnet_cols + vgg_cols\n",
    "\n",
    "X = stacking_df[feature_cols]\n",
    "y = stacking_df['TrueLabel']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "meta_model = RandomForestClassifier(random_state=42)\n",
    "meta_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the evaluation split using the meta model\n",
    "y_pred = meta_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Model Evaluation Metrics:\n",
      "===============================\n",
      "Accuracy:   0.8708\n",
      "Precision:  0.8729\n",
      "Recall:     0.8708\n",
      "F1 Score:   0.8712\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Meta Model Evaluation Metrics:\")\n",
    "print(\"===============================\")\n",
    "print(f\"Accuracy:   {accuracy:.4f}\")\n",
    "print(f\"Precision:  {precision:.4f}\")\n",
    "print(f\"Recall:     {recall:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(\"===============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
